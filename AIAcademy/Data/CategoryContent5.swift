import Foundation

struct CategoryContent5 {
    static let aiEthics = CategoryData(
        id: "ai_ethics", name: "AI Ethics & Safety", icon: "shield.checkered", colorName: "aiRed",
        description: "Bias, fairness, alignment, deepfakes, misinformation, regulation",
        lessons: [lesson1, lesson2, lesson3, lesson4, lesson5, lesson6], order: 4,
        unlockRequirement: .completeCategoryMinimum("how_ai_learns")
    )
    static let lesson1 = LessonData(id: "ae_l1", title: "Understanding AI Bias", description: "When AI isn't fair", categoryId: "ai_ethics", questions: [
        Question(id: "ae1_q1", type: .multipleChoice, questionText: "AI bias most often comes from:", options: ["Biased training data", "Malicious code", "Random chance", "User error only"], correctAnswer: "Biased training data", explanation: "Most AI bias originates from unrepresentative or historically biased training data."),
        Question(id: "ae1_q2", type: .trueFalse, questionText: "AI systems can perpetuate racial and gender biases.", options: ["True", "False"], correctAnswer: "True", explanation: "If trained on historically biased data, AI can reproduce and even amplify societal biases."),
        Question(id: "ae1_q3", type: .scenarioJudgment, questionText: "A hiring AI rejects more resumes from women because historical data shows the company previously hired mostly men. Is this acceptable?", options: ["No, it's discriminatory", "Yes, it's data-driven", "It depends"], correctAnswer: "No, it's discriminatory", explanation: "This is a well-documented case of AI perpetuating historical gender bias in hiring."),
        Question(id: "ae1_q4", type: .fillInBlank, questionText: "AI __________ occurs when a system systematically produces unfair results for certain groups.", options: ["bias", "speed", "cost", "size"], correctAnswer: "bias", explanation: "AI bias leads to systematically unfair outcomes that can harm underrepresented or marginalized groups."),
        Question(id: "ae1_q5", type: .multipleChoice, questionText: "Which approach helps reduce AI bias?", options: ["Diverse teams and diverse data", "Using less data", "Ignoring the problem", "Making the AI faster"], correctAnswer: "Diverse teams and diverse data", explanation: "Diverse development teams can spot biases that homogeneous teams might miss, and diverse data reduces skewed learning."),
        Question(id: "ae1_q6", type: .multipleChoice, questionText: "What is 'algorithmic fairness'?", options: ["Designing AI to treat all groups equitably", "Making algorithms run faster", "Using simple algorithms", "Opening all source code"], correctAnswer: "Designing AI to treat all groups equitably", explanation: "Algorithmic fairness is the practice of ensuring AI systems don't systematically disadvantage any group.")
    ], order: 0, difficulty: .beginner)
    static let lesson2 = LessonData(id: "ae_l2", title: "Deepfakes & Misinformation", description: "AI-generated deception", categoryId: "ai_ethics", questions: [
        Question(id: "ae2_q1", type: .multipleChoice, questionText: "A deepfake is:", options: ["AI-generated fake video or audio of real people", "A deep learning framework", "A type of encryption", "A debugging technique"], correctAnswer: "AI-generated fake video or audio of real people", explanation: "Deepfakes use AI to create realistic but fake videos, images, or audio recordings of real people."),
        Question(id: "ae2_q2", type: .trueFalse, questionText: "It's always easy to tell if a video is a deepfake.", options: ["True", "False"], correctAnswer: "False", explanation: "Modern deepfakes are increasingly convincing, making them difficult for humans to detect without tools."),
        Question(id: "ae2_q3", type: .scenarioJudgment, questionText: "Someone creates a deepfake video of a politician saying something they never said. What should happen?", options: ["The content should be flagged and removed", "It's protected free speech", "It depends"], correctAnswer: "The content should be flagged and removed", explanation: "Deepfake political content is a form of misinformation that can undermine democracy and should be addressed."),
        Question(id: "ae2_q4", type: .multipleChoice, questionText: "Which technology is used to detect deepfakes?", options: ["AI-powered detection tools", "Magnifying glasses", "Spell checkers", "Antivirus software"], correctAnswer: "AI-powered detection tools", explanation: "Ironically, AI is also used to detect AI-generated deepfakes by analyzing subtle artifacts."),
        Question(id: "ae2_q5", type: .fillInBlank, questionText: "AI-generated __________ is false or misleading content created to deceive people.", options: ["misinformation", "education", "entertainment", "software"], correctAnswer: "misinformation", explanation: "AI makes it easier to create convincing misinformation at scale, posing a major societal challenge."),
        Question(id: "ae2_q6", type: .matchPairs, questionText: "Match deepfake concerns:", matchPairs: [
            MatchPair(term: "Political deepfakes", definition: "Undermining elections"),
            MatchPair(term: "Voice cloning", definition: "Impersonating people by phone"),
            MatchPair(term: "Fake news", definition: "Spreading false information"),
            MatchPair(term: "Identity theft", definition: "Impersonating someone's likeness")
        ], explanation: "Deepfakes pose a range of threats from political manipulation to personal fraud.")
    ], order: 1, difficulty: .intermediate)
    static let lesson3 = LessonData(id: "ae_l3", title: "AI Alignment", description: "Making AI do what we want", categoryId: "ai_ethics", questions: [
        Question(id: "ae3_q1", type: .multipleChoice, questionText: "AI alignment refers to:", options: ["Ensuring AI goals match human values", "Aligning text on a page", "Physical alignment of servers", "Network alignment protocols"], correctAnswer: "Ensuring AI goals match human values", explanation: "Alignment is the challenge of making sure AI systems pursue goals that are beneficial and consistent with human values."),
        Question(id: "ae3_q2", type: .trueFalse, questionText: "A perfectly performing AI is automatically aligned with human values.", options: ["True", "False"], correctAnswer: "False", explanation: "An AI can optimize perfectly for its given objective but still cause harm if that objective doesn't capture human values."),
        Question(id: "ae3_q3", type: .fillInBlank, questionText: "The __________ problem describes the challenge of specifying goals for AI that truly match human intent.", options: ["alignment", "coding", "speed", "hardware"], correctAnswer: "alignment", explanation: "The alignment problem is one of the most important open challenges in AI safety."),
        Question(id: "ae3_q4", type: .scenarioJudgment, questionText: "An AI tasked with maximizing paper clip production converts all available resources into paper clips, including those needed by humans. What went wrong?", options: ["The AI's goal was misaligned", "The AI was too slow", "Nothing went wrong", "It depends"], correctAnswer: "The AI's goal was misaligned", explanation: "This is the famous 'paperclip maximizer' thought experiment illustrating the dangers of misaligned AI objectives."),
        Question(id: "ae3_q5", type: .multipleChoice, questionText: "RLHF stands for:", options: ["Reinforcement Learning from Human Feedback", "Rapid Learning for Hardware Functions", "Random Learning from Historical Files", "Real-time Language for Human Facts"], correctAnswer: "Reinforcement Learning from Human Feedback", explanation: "RLHF is a technique used to align AI models with human preferences by incorporating human feedback."),
        Question(id: "ae3_q6", type: .multipleChoice, questionText: "Why is AI alignment difficult?", options: ["Human values are complex and hard to formalize", "Computers are too slow", "We don't have enough programmers", "AI always agrees with humans"], correctAnswer: "Human values are complex and hard to formalize", explanation: "Human values are nuanced, context-dependent, and sometimes contradictory — making them extremely hard to encode in AI.")
    ], order: 2, difficulty: .advanced)
    static let lesson4 = LessonData(id: "ae_l4", title: "Privacy & Surveillance", description: "AI and your personal data", categoryId: "ai_ethics", questions: [
        Question(id: "ae4_q1", type: .multipleChoice, questionText: "Facial recognition AI raises concerns about:", options: ["Mass surveillance and privacy invasion", "Making cameras cheaper", "Improving photo quality", "Faster internet"], correctAnswer: "Mass surveillance and privacy invasion", explanation: "Facial recognition enables tracking individuals without their consent, raising serious privacy concerns."),
        Question(id: "ae4_q2", type: .trueFalse, questionText: "Some cities have banned government use of facial recognition technology.", options: ["True", "False"], correctAnswer: "True", explanation: "Cities like San Francisco and Boston have banned government use of facial recognition over privacy concerns."),
        Question(id: "ae4_q3", type: .fillInBlank, questionText: "AI systems that collect and analyze personal data must comply with __________ regulations.", options: ["privacy", "speed", "gaming", "weather"], correctAnswer: "privacy", explanation: "Laws like GDPR (Europe) and CCPA (California) regulate how personal data is collected and used by AI systems."),
        Question(id: "ae4_q4", type: .scenarioJudgment, questionText: "A store uses AI cameras to track customers' emotions while shopping to optimize product placement. Is this ethical?", options: ["No, it's invasive", "Yes, it's innovation", "It depends"], correctAnswer: "No, it's invasive", explanation: "Monitoring customers' emotions without explicit consent is a significant invasion of privacy."),
        Question(id: "ae4_q5", type: .multipleChoice, questionText: "What does 'data minimization' mean?", options: ["Collecting only the data you actually need", "Minimizing data storage costs", "Deleting all data immediately", "Using the smallest database possible"], correctAnswer: "Collecting only the data you actually need", explanation: "Data minimization is a privacy principle: only collect the minimum data necessary for the stated purpose."),
        Question(id: "ae4_q6", type: .multipleChoice, questionText: "GDPR is:", options: ["A European data protection regulation", "A type of AI model", "A programming language", "A hardware standard"], correctAnswer: "A European data protection regulation", explanation: "The General Data Protection Regulation is the EU's comprehensive data privacy law affecting AI systems.")
    ], order: 3, difficulty: .intermediate)
    static let lesson5 = LessonData(id: "ae_l5", title: "AI Regulation", description: "Laws governing AI", categoryId: "ai_ethics", questions: [
        Question(id: "ae5_q1", type: .multipleChoice, questionText: "The EU AI Act classifies AI systems by:", options: ["Risk level (minimal to unacceptable)", "Processing speed", "Cost of development", "Number of users"], correctAnswer: "Risk level (minimal to unacceptable)", explanation: "The EU AI Act takes a risk-based approach, with stricter rules for higher-risk AI applications."),
        Question(id: "ae5_q2", type: .trueFalse, questionText: "Currently, there is a single global standard for AI regulation.", options: ["True", "False"], correctAnswer: "False", explanation: "AI regulation varies significantly by country and region — there is no unified global standard yet."),
        Question(id: "ae5_q3", type: .matchPairs, questionText: "Match regulation approaches:", matchPairs: [
            MatchPair(term: "EU AI Act", definition: "Risk-based classification system"),
            MatchPair(term: "US approach", definition: "Sector-specific guidelines"),
            MatchPair(term: "China", definition: "Government-controlled AI governance"),
            MatchPair(term: "OECD AI Principles", definition: "International voluntary guidelines")
        ], explanation: "Different regions take fundamentally different approaches to AI regulation."),
        Question(id: "ae5_q4", type: .fillInBlank, questionText: "AI __________ is the framework of rules and guidelines governing how AI can be developed and used.", options: ["regulation", "acceleration", "deletion", "compression"], correctAnswer: "regulation", explanation: "AI regulation aims to balance innovation with protection of individual rights and societal well-being."),
        Question(id: "ae5_q5", type: .scenarioJudgment, questionText: "A government mandates that all AI systems must be explainable before deployment. Is this a good policy?", options: ["Yes, transparency matters", "No, it's too restrictive", "It depends"], correctAnswer: "It depends", explanation: "Explainability is important but the right level depends on the application — medical AI needs more than a game recommendation."),
        Question(id: "ae5_q6", type: .multipleChoice, questionText: "What is 'AI transparency'?", options: ["Making AI decision-making understandable", "Making AI code open source", "Making AI free to use", "Making AI faster"], correctAnswer: "Making AI decision-making understandable", explanation: "AI transparency means stakeholders can understand how and why an AI system makes its decisions.")
    ], order: 4, difficulty: .advanced)
    static let lesson6 = LessonData(id: "ae_l6", title: "Responsible AI Development", description: "Building AI the right way", categoryId: "ai_ethics", questions: [
        Question(id: "ae6_q1", type: .multipleChoice, questionText: "Which is a pillar of responsible AI?", options: ["Fairness, accountability, and transparency", "Speed, cost, and profit", "Secrecy, complexity, and scale", "Marketing, sales, and growth"], correctAnswer: "Fairness, accountability, and transparency", explanation: "Responsible AI is built on principles of fairness, accountability, transparency, and safety."),
        Question(id: "ae6_q2", type: .trueFalse, questionText: "Companies developing AI have no ethical obligations beyond legal requirements.", options: ["True", "False"], correctAnswer: "False", explanation: "Ethical AI development goes beyond legal compliance — it requires proactively considering societal impact."),
        Question(id: "ae6_q3", type: .fillInBlank, questionText: "An AI __________ board helps organizations make ethical decisions about AI deployment.", options: ["ethics", "marketing", "sales", "gaming"], correctAnswer: "ethics", explanation: "AI ethics boards provide guidance on the ethical implications of AI projects and policies."),
        Question(id: "ae6_q4", type: .scenarioJudgment, questionText: "A company discovers their AI product has a bias but fixing it would delay the launch by 3 months. Should they delay?", options: ["Yes, fix the bias first", "No, launch and fix later", "It depends"], correctAnswer: "Yes, fix the bias first", explanation: "Deploying a known biased system can cause real harm. Responsible development prioritizes fixing issues before launch."),
        Question(id: "ae6_q5", type: .multipleChoice, questionText: "What is an AI impact assessment?", options: ["Evaluating potential effects of AI on people and society", "Measuring AI speed", "Counting users of an AI system", "Testing AI hardware performance"], correctAnswer: "Evaluating potential effects of AI on people and society", explanation: "Impact assessments help identify and mitigate potential negative consequences before deploying AI systems."),
        Question(id: "ae6_q6", type: .multipleChoice, questionText: "Which is most important for responsible AI?", options: ["Ongoing monitoring after deployment", "Only testing before launch", "Assuming AI is always correct", "Avoiding all risk"], correctAnswer: "Ongoing monitoring after deployment", explanation: "AI systems can develop issues over time as data changes, making continuous monitoring essential.")
    ], order: 5, difficulty: .advanced)
}
