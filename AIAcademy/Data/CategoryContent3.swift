import Foundation

struct CategoryContent3 {
    static let generativeAI = CategoryData(
        id: "generative_ai", name: "Generative AI", icon: "sparkles", colorName: "aiPink",
        description: "LLMs, transformers, GPT, Claude, diffusion models, hallucinations",
        lessons: [lesson1, lesson2, lesson3, lesson4, lesson5, lesson6], order: 2,
        unlockRequirement: .completeCategory("how_ai_learns")
    )
    static let lesson1 = LessonData(id: "ga_l1", title: "What is Generative AI?", description: "AI that creates new content", categoryId: "generative_ai", questions: [
        Question(id: "ga1_q1", type: .multipleChoice, questionText: "Generative AI is AI that:", options: ["Creates new content like text, images, or code", "Only analyzes existing data", "Generates electricity", "Only deletes content"], correctAnswer: "Creates new content like text, images, or code", explanation: "Generative AI produces new content — text, images, music, code — that didn't exist before."),
        Question(id: "ga1_q2", type: .trueFalse, questionText: "ChatGPT is an example of generative AI.", options: ["True", "False"], correctAnswer: "True", explanation: "ChatGPT generates new text responses, making it a generative AI system."),
        Question(id: "ga1_q3", type: .fillInBlank, questionText: "A __________ is a type of AI that generates new content like text, images, or code.", options: ["generative model", "search engine", "database", "compiler"], correctAnswer: "generative model", explanation: "Generative models learn patterns from training data and use them to create new, similar content."),
        Question(id: "ga1_q4", type: .multipleChoice, questionText: "Which is NOT an output of generative AI?", options: ["Physical objects from thin air", "Written essays", "Generated images", "Computer code"], correctAnswer: "Physical objects from thin air", explanation: "Generative AI creates digital content — it cannot create physical objects without manufacturing equipment."),
        Question(id: "ga1_q5", type: .matchPairs, questionText: "Match generative AI tools to what they create:", matchPairs: [
            MatchPair(term: "ChatGPT", definition: "Text and conversations"),
            MatchPair(term: "DALL-E", definition: "Images from descriptions"),
            MatchPair(term: "GitHub Copilot", definition: "Programming code"),
            MatchPair(term: "Suno", definition: "Music and songs")
        ], explanation: "Different generative AI tools specialize in creating different types of content."),
        Question(id: "ga1_q6", type: .scenarioJudgment, questionText: "A student submits an essay entirely written by generative AI without disclosure. Is this appropriate?", options: ["No, it's problematic", "Yes, it's fine", "It depends"], correctAnswer: "No, it's problematic", explanation: "Submitting AI-generated work as your own without disclosure is generally considered academic dishonesty.")
    ], order: 0, difficulty: .beginner)
    static let lesson2 = LessonData(id: "ga_l2", title: "Large Language Models", description: "The brains behind chatbots", categoryId: "generative_ai", questions: [
        Question(id: "ga2_q1", type: .multipleChoice, questionText: "What does 'LLM' stand for?", options: ["Large Language Model", "Linear Learning Machine", "Layered Logic Module", "Language Linking Method"], correctAnswer: "Large Language Model", explanation: "LLM stands for Large Language Model — AI trained on vast amounts of text data."),
        Question(id: "ga2_q2", type: .trueFalse, questionText: "LLMs understand language the same way humans do.", options: ["True", "False"], correctAnswer: "False", explanation: "LLMs predict the most likely next word based on patterns. They don't truly understand meaning like humans."),
        Question(id: "ga2_q3", type: .fillInBlank, questionText: "LLMs are trained on __________ amounts of text from the internet, books, and other sources.", options: ["massive", "tiny", "zero", "negative"], correctAnswer: "massive", explanation: "LLMs like GPT-4 are trained on hundreds of billions of words from diverse text sources."),
        Question(id: "ga2_q4", type: .multipleChoice, questionText: "How do LLMs generate text?", options: ["By predicting the most likely next word", "By looking up answers in a database", "By copying from the internet in real-time", "By reading minds"], correctAnswer: "By predicting the most likely next word", explanation: "LLMs work by predicting the next token (word/subword) in a sequence, one at a time."),
        Question(id: "ga2_q5", type: .matchPairs, questionText: "Match LLMs to their creators:", matchPairs: [
            MatchPair(term: "GPT-4", definition: "OpenAI"),
            MatchPair(term: "Claude", definition: "Anthropic"),
            MatchPair(term: "Gemini", definition: "Google"),
            MatchPair(term: "LLaMA", definition: "Meta")
        ], explanation: "Several major tech companies and AI labs have developed their own large language models."),
        Question(id: "ga2_q6", type: .multipleChoice, questionText: "What is a 'parameter' in an LLM?", options: ["A learned numerical value in the model", "A command you type", "A physical component", "A type of programming language"], correctAnswer: "A learned numerical value in the model", explanation: "Parameters are the millions or billions of numerical values that the model learns during training.")
    ], order: 1, difficulty: .intermediate)
    static let lesson3 = LessonData(id: "ga_l3", title: "Transformers Architecture", description: "The technology behind modern AI", categoryId: "generative_ai", questions: [
        Question(id: "ga3_q1", type: .multipleChoice, questionText: "The Transformer architecture was introduced in a paper titled:", options: ["Attention Is All You Need", "The Future of Computing", "Neural Networks 101", "Deep Learning Basics"], correctAnswer: "Attention Is All You Need", explanation: "The landmark 2017 paper by Google researchers introduced the Transformer architecture that powers modern LLMs."),
        Question(id: "ga3_q2", type: .trueFalse, questionText: "The attention mechanism helps models focus on relevant parts of the input.", options: ["True", "False"], correctAnswer: "True", explanation: "Self-attention allows the model to weigh the importance of different parts of the input when processing each word."),
        Question(id: "ga3_q3", type: .fillInBlank, questionText: "The __________ mechanism is the key innovation in the Transformer architecture.", options: ["attention", "deletion", "compression", "copying"], correctAnswer: "attention", explanation: "Attention lets the model dynamically focus on the most relevant parts of the input sequence."),
        Question(id: "ga3_q4", type: .multipleChoice, questionText: "Why are Transformers better than previous models for language?", options: ["They can process entire sequences in parallel", "They use less memory", "They don't need data", "They are physically smaller"], correctAnswer: "They can process entire sequences in parallel", explanation: "Unlike previous models that processed words one at a time, Transformers process entire sequences at once."),
        Question(id: "ga3_q5", type: .multipleChoice, questionText: "What does 'tokenization' mean in the context of LLMs?", options: ["Breaking text into smaller pieces for processing", "Creating digital currency", "Encrypting messages", "Compressing files"], correctAnswer: "Breaking text into smaller pieces for processing", explanation: "Tokenization splits text into tokens (words, subwords, or characters) that the model can process."),
        Question(id: "ga3_q6", type: .sortOrder, questionText: "Order the evolution of language AI:", options: ["Large Language Models", "Rule-based systems", "Transformer architecture", "Recurrent Neural Networks"], correctAnswers: ["Rule-based systems", "Recurrent Neural Networks", "Transformer architecture", "Large Language Models"], explanation: "Language AI evolved from simple rules to sophisticated LLMs built on Transformers.")
    ], order: 2, difficulty: .advanced)
    static let lesson4 = LessonData(id: "ga_l4", title: "AI Hallucinations", description: "When AI makes things up", categoryId: "generative_ai", questions: [
        Question(id: "ga4_q1", type: .multipleChoice, questionText: "An 'AI hallucination' is when:", options: ["AI generates false information that sounds convincing", "AI sees visual hallucinations", "AI refuses to respond", "AI runs out of memory"], correctAnswer: "AI generates false information that sounds convincing", explanation: "Hallucinations are fabricated outputs that sound plausible but are factually incorrect."),
        Question(id: "ga4_q2", type: .trueFalse, questionText: "AI hallucinations are a solved problem in modern LLMs.", options: ["True", "False"], correctAnswer: "False", explanation: "Hallucinations remain one of the biggest unsolved challenges in AI. All current LLMs can hallucinate."),
        Question(id: "ga4_q3", type: .scenarioJudgment, questionText: "A lawyer uses ChatGPT to find legal cases and cites them in court without checking. The cases turn out to be fabricated. Who is at fault?", options: ["The lawyer", "Only the AI", "It depends"], correctAnswer: "The lawyer", explanation: "Professionals are responsible for verifying AI outputs. The lawyer should have checked that the cases were real."),
        Question(id: "ga4_q4", type: .fillInBlank, questionText: "You should always __________ important information generated by AI before relying on it.", options: ["verify", "ignore", "delete", "share"], correctAnswer: "verify", explanation: "Always fact-check AI outputs, especially for important decisions, since LLMs can confidently state false information."),
        Question(id: "ga4_q5", type: .multipleChoice, questionText: "Why do LLMs hallucinate?", options: ["They predict likely text patterns, not verified facts", "They intentionally lie", "They have emotions", "They are poorly programmed"], correctAnswer: "They predict likely text patterns, not verified facts", explanation: "LLMs generate statistically likely text, not verified facts. They don't have a database of truth to check against."),
        Question(id: "ga4_q6", type: .multipleChoice, questionText: "Which strategy helps reduce the impact of AI hallucinations?", options: ["Cross-referencing with reliable sources", "Asking the AI if it's sure", "Assuming AI is always correct", "Using older AI models"], correctAnswer: "Cross-referencing with reliable sources", explanation: "The best defense against hallucinations is verifying AI outputs against trusted, authoritative sources.")
    ], order: 3, difficulty: .intermediate)
    static let lesson5 = LessonData(id: "ga_l5", title: "Image Generation AI", description: "Creating pictures with words", categoryId: "generative_ai", questions: [
        Question(id: "ga5_q1", type: .multipleChoice, questionText: "Image generation AI creates images from:", options: ["Text descriptions (prompts)", "Physical drawings only", "Camera input only", "Random noise only"], correctAnswer: "Text descriptions (prompts)", explanation: "Text-to-image models like DALL-E and Midjourney generate images based on written descriptions."),
        Question(id: "ga5_q2", type: .trueFalse, questionText: "Diffusion models work by gradually removing noise from a random image.", options: ["True", "False"], correctAnswer: "True", explanation: "Diffusion models start with pure noise and gradually denoise it, guided by the text prompt, to create an image."),
        Question(id: "ga5_q3", type: .matchPairs, questionText: "Match image AI tools:", matchPairs: [
            MatchPair(term: "DALL-E", definition: "OpenAI's image generator"),
            MatchPair(term: "Midjourney", definition: "Known for artistic style"),
            MatchPair(term: "Stable Diffusion", definition: "Open-source image model"),
            MatchPair(term: "Firefly", definition: "Adobe's creative AI")
        ], explanation: "Multiple companies have developed image generation AI, each with different strengths."),
        Question(id: "ga5_q4", type: .fillInBlank, questionText: "__________ models work by learning to remove noise from images step by step.", options: ["Diffusion", "Confusion", "Compression", "Deletion"], correctAnswer: "Diffusion", explanation: "Diffusion models are trained to reverse a noise-adding process, gradually creating clear images from random noise."),
        Question(id: "ga5_q5", type: .scenarioJudgment, questionText: "An artist discovers their style has been replicated by an AI image generator trained on their work without permission. Is this ethical?", options: ["No, it's problematic", "Yes, it's fine", "It depends"], correctAnswer: "No, it's problematic", explanation: "Using artists' work to train AI without consent raises serious ethical and copyright concerns."),
        Question(id: "ga5_q6", type: .multipleChoice, questionText: "What can current image AI NOT do well?", options: ["Consistently generate correct text in images", "Create photorealistic landscapes", "Generate faces", "Produce abstract art"], correctAnswer: "Consistently generate correct text in images", explanation: "Image AI often struggles with rendering text correctly, producing misspelled or garbled words in images.")
    ], order: 4, difficulty: .intermediate)
    static let lesson6 = LessonData(id: "ga_l6", title: "Responsible Use of Generative AI", description: "Ethics and best practices", categoryId: "generative_ai", questions: [
        Question(id: "ga6_q1", type: .multipleChoice, questionText: "When using generative AI for work, you should:", options: ["Always disclose AI use and review outputs", "Keep it secret from everyone", "Trust AI output completely", "Avoid using it entirely"], correctAnswer: "Always disclose AI use and review outputs", explanation: "Transparency about AI use and verifying outputs are key principles of responsible generative AI usage."),
        Question(id: "ga6_q2", type: .trueFalse, questionText: "It's generally safe to input confidential business data into public AI chatbots.", options: ["True", "False"], correctAnswer: "False", explanation: "Public AI services may use inputs for training. Confidential data should not be shared with public AI tools."),
        Question(id: "ga6_q3", type: .scenarioJudgment, questionText: "A company creates AI-generated marketing images featuring diverse people who don't exist. Should they disclose this?", options: ["Yes, disclose it", "No, no need", "It depends"], correctAnswer: "Yes, disclose it", explanation: "Using AI-generated people in marketing should be disclosed to maintain trust and avoid misleading consumers."),
        Question(id: "ga6_q4", type: .fillInBlank, questionText: "The concept of keeping humans involved in AI decision-making is called 'human in the __________.'", options: ["loop", "cloud", "server", "code"], correctAnswer: "loop", explanation: "Human-in-the-loop means keeping humans involved in reviewing and making final decisions on AI outputs."),
        Question(id: "ga6_q5", type: .multipleChoice, questionText: "What is the best practice when AI-generated content will be published?", options: ["Review, edit, and fact-check before publishing", "Publish immediately without review", "Add a disclaimer that you didn't read it", "Only publish if the AI says it's accurate"], correctAnswer: "Review, edit, and fact-check before publishing", explanation: "AI outputs should always be reviewed by a human for accuracy, tone, and appropriateness before publication."),
        Question(id: "ga6_q6", type: .multipleChoice, questionText: "Which is a key concern about generative AI and misinformation?", options: ["AI can create convincing fake content at scale", "AI always tells the truth", "AI content is easy to identify", "AI cannot create fake content"], correctAnswer: "AI can create convincing fake content at scale", explanation: "Generative AI makes it easy to create realistic fake text, images, and videos, raising concerns about misinformation.")
    ], order: 5, difficulty: .intermediate)
}
